{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "#test if gpu is wokring\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print(tf.test.gpu_device_name())\n",
    "\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:\\\\User_Data\\\\Desktop\\\\kan-2\\\\NeuralNetwork\\\\\"\n",
    "import os\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary package\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 8)                 848       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 929\n",
      "Trainable params: 929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model complie\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=105, kernel_initializer='normal', activation='relu'))#input_dim=number of columns original :relu\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))#Here the source is using linear \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_stata(\"CD_icd.dta\")\n",
    "df=pd.read_stata(\"CD_icd.dta\",convert_missing=False)\n",
    "df=df.dropna()\n",
    "x_vars=[\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\",\"month1\",\"month2\",\"month3\",\"month4\",\"month5\",\"month6\"\n",
    "  ,\"month7\",\"month8\",\"month9\",\"month10\",\"month11\",\"month12\",\"male\",\"age\",\"icd_0diab2_365\",\"icd_0liver_365\",\"icd_0cardio_365\",\"icd_0hbp_365\"]\n",
    "for i in df.columns:\n",
    "    if \"icd\" in i and i not in x_vars:\n",
    "        x_vars.append(i)\n",
    "x=df[x_vars]\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#poly = PolynomialFeatures(degree=2,interaction_only=True,include_bias = False)\n",
    "#x=poly.fit_transform(x)\n",
    "y=df[[\"drug_amt\"]]\n",
    "#icd_auri1\n",
    "scaler_x = MinMaxScaler()#able to change to other \n",
    "scaler_y = MinMaxScaler()#able to change\n",
    "#print(scaler_x.fit(x))\n",
    "#xscale=scaler_x.transform(x)\n",
    "#print(scaler_y.fit(y))\n",
    "#yscale=scaler_y.transform(y)\n",
    "xscale=x\n",
    "yscale=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12943/12943 [==============================] - 10s 802us/step - loss: 1597281.8750 - mse: 1597281.8750 - mae: 331.3897 - val_loss: 1143063.3750 - val_mse: 1143063.3750 - val_mae: 325.5528\n",
      "Epoch 2/500\n",
      "12943/12943 [==============================] - 10s 797us/step - loss: 1597283.6250 - mse: 1597283.6250 - mae: 331.3901 - val_loss: 1143063.3750 - val_mse: 1143063.3750 - val_mae: 325.5528\n",
      "Epoch 3/500\n",
      "12943/12943 [==============================] - 10s 787us/step - loss: 1597279.1250 - mse: 1597279.1250 - mae: 331.3908 - val_loss: 1143063.3750 - val_mse: 1143063.3750 - val_mae: 325.5528\n",
      "Epoch 4/500\n",
      "12943/12943 [==============================] - 10s 799us/step - loss: 1597285.6250 - mse: 1597285.6250 - mae: 331.3904 - val_loss: 1143063.3750 - val_mse: 1143063.3750 - val_mae: 325.5528\n",
      "Epoch 5/500\n",
      "12943/12943 [==============================] - 10s 793us/step - loss: 1597276.2500 - mse: 1597276.2500 - mae: 331.3905 - val_loss: 1143063.3750 - val_mse: 1143063.3750 - val_mae: 325.5528\n",
      "Epoch 6/500\n",
      "11919/12943 [==========================>...] - ETA: 0s - loss: 1594240.2500 - mse: 1594240.2500 - mae: 330.9476"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c27c3b1a0936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#epochs=max steps batch_size=numer of sample will be trained at once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y, epochs=500, batch_size=50,  verbose=1, validation_split=0.2)#epochs=max steps batch_size=numer of sample will be trained at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1290684.0057270916\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in mse_result:\n",
    "    k=k+i\n",
    "print(k/len(mse_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter=0\n",
    "mse_result=[]\n",
    "while counter<=250:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)\n",
    "    #Standard OLS performance\n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit (X_train,y_train)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    y_pred=reg.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mse_result.append(mse)\n",
    "    counter=counter+1\n",
    "    #mse = ((y_test-y_pred)**2).mean(axis=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1264339.1,\n",
       " 1165512.6,\n",
       " 1193384.8,\n",
       " 1368927.8,\n",
       " 1252641.1,\n",
       " 1205502.8,\n",
       " 1312303.9,\n",
       " 1392657.9,\n",
       " 1325341.8,\n",
       " 1255855.0,\n",
       " 1425882.0,\n",
       " 1311523.9,\n",
       " 1449466.9,\n",
       " 1294085.8,\n",
       " 1314952.5,\n",
       " 1287513.4,\n",
       " 1248532.9,\n",
       " 1177241.1,\n",
       " 1027727.8,\n",
       " 1337614.0,\n",
       " 1335619.6,\n",
       " 1363138.9,\n",
       " 1371232.0,\n",
       " 1239413.6,\n",
       " 1214481.5,\n",
       " 1261798.6,\n",
       " 1245965.5,\n",
       " 1113866.9,\n",
       " 1303190.8,\n",
       " 1398021.2,\n",
       " 1418783.0,\n",
       " 1397415.5,\n",
       " 1225949.9,\n",
       " 1402218.2,\n",
       " 1341407.1,\n",
       " 1277041.4,\n",
       " 1288355.0,\n",
       " 1230199.9,\n",
       " 1148848.4,\n",
       " 1208224.9,\n",
       " 1269293.1,\n",
       " 1490206.9,\n",
       " 1211789.4,\n",
       " 1415818.0,\n",
       " 1338381.9,\n",
       " 1224530.4,\n",
       " 1285846.5,\n",
       " 1333495.8,\n",
       " 1156128.8,\n",
       " 1317940.5,\n",
       " 1119962.5,\n",
       " 1419708.4,\n",
       " 1279503.6,\n",
       " 1221379.9,\n",
       " 1269365.0,\n",
       " 1121339.9,\n",
       " 1220002.8,\n",
       " 1339577.1,\n",
       " 1390597.1,\n",
       " 1252881.6,\n",
       " 1187970.1,\n",
       " 1238791.5,\n",
       " 1377137.2,\n",
       " 1299929.8,\n",
       " 1215083.2,\n",
       " 1199533.5,\n",
       " 1188856.6,\n",
       " 1213820.5,\n",
       " 1347780.0,\n",
       " 1297195.5,\n",
       " 1371952.4,\n",
       " 1304861.6,\n",
       " 1236138.1,\n",
       " 1271544.4,\n",
       " 1282900.9,\n",
       " 1344090.8,\n",
       " 1220098.6,\n",
       " 1408716.6,\n",
       " 1123949.9,\n",
       " 1350606.8,\n",
       " 1207463.8,\n",
       " 1350864.6,\n",
       " 1459634.6,\n",
       " 1162766.5,\n",
       " 1303370.9,\n",
       " 1328494.2,\n",
       " 1226540.2,\n",
       " 1382854.5,\n",
       " 1284502.2,\n",
       " 1304203.1,\n",
       " 1293903.5,\n",
       " 1240619.6,\n",
       " 1271511.9,\n",
       " 1177732.4,\n",
       " 1541738.8,\n",
       " 1353241.0,\n",
       " 1422878.0,\n",
       " 1264608.8,\n",
       " 1142417.6,\n",
       " 1293899.5,\n",
       " 1416917.5,\n",
       " 1292961.2,\n",
       " 1192459.1,\n",
       " 1283038.6,\n",
       " 1397157.5,\n",
       " 1144505.0,\n",
       " 1459453.5,\n",
       " 1279099.0,\n",
       " 1483758.5,\n",
       " 1488756.8,\n",
       " 1169485.4,\n",
       " 1237793.9,\n",
       " 1392996.6,\n",
       " 1375982.6,\n",
       " 1181800.2,\n",
       " 1348725.6,\n",
       " 1221870.1,\n",
       " 1264790.1,\n",
       " 1325998.4,\n",
       " 1185321.2,\n",
       " 1325601.8,\n",
       " 1362168.5,\n",
       " 1184088.9,\n",
       " 1330259.5,\n",
       " 1159802.8,\n",
       " 1311810.8,\n",
       " 1277122.9,\n",
       " 1235319.6,\n",
       " 1370680.8,\n",
       " 1292701.6,\n",
       " 1317722.4,\n",
       " 1345103.5,\n",
       " 1138379.5,\n",
       " 1199730.2,\n",
       " 1372051.4,\n",
       " 1266994.4,\n",
       " 1197125.2,\n",
       " 1128392.1,\n",
       " 1366491.2,\n",
       " 1299165.6,\n",
       " 1274746.8,\n",
       " 1176254.2,\n",
       " 1294569.4,\n",
       " 1194158.9,\n",
       " 1142556.5,\n",
       " 1239646.4,\n",
       " 1313891.8,\n",
       " 1331628.1,\n",
       " 1366803.1,\n",
       " 1345639.5,\n",
       " 1582720.6,\n",
       " 1361237.2,\n",
       " 1168735.1,\n",
       " 1274210.5,\n",
       " 1372023.4,\n",
       " 1525661.4,\n",
       " 1357225.1,\n",
       " 1349540.2,\n",
       " 1221176.1,\n",
       " 1277090.1,\n",
       " 1240882.8,\n",
       " 1295680.4,\n",
       " 1348754.4,\n",
       " 1276207.1,\n",
       " 1251896.6,\n",
       " 1373882.4,\n",
       " 1261470.0,\n",
       " 1279720.4,\n",
       " 1237237.1,\n",
       " 1218648.8,\n",
       " 1269201.5,\n",
       " 1281802.2,\n",
       " 1437059.1,\n",
       " 1152664.9,\n",
       " 1223632.6,\n",
       " 1337514.5,\n",
       " 1296678.8,\n",
       " 1271920.4,\n",
       " 1408770.2,\n",
       " 1290835.2,\n",
       " 1299314.9,\n",
       " 1285652.8,\n",
       " 1233779.0,\n",
       " 1274508.6,\n",
       " 1240935.9,\n",
       " 1294413.1,\n",
       " 1438461.9,\n",
       " 1328452.2,\n",
       " 1244121.8,\n",
       " 1171377.9,\n",
       " 1235554.9,\n",
       " 1384388.6,\n",
       " 1388998.6,\n",
       " 1397250.4,\n",
       " 1264856.6,\n",
       " 1243641.1,\n",
       " 1192758.6,\n",
       " 1102130.6,\n",
       " 1228735.5,\n",
       " 1494089.8,\n",
       " 1313982.0,\n",
       " 1448005.9,\n",
       " 1319941.8,\n",
       " 1280320.6,\n",
       " 1205610.5,\n",
       " 1170123.9,\n",
       " 1234273.1,\n",
       " 1285178.9,\n",
       " 1403209.1,\n",
       " 1226192.5,\n",
       " 1321065.1,\n",
       " 1329648.8,\n",
       " 1245606.0,\n",
       " 1433762.8,\n",
       " 1343866.6,\n",
       " 1347920.1,\n",
       " 1407601.4,\n",
       " 1339254.0,\n",
       " 1350538.8,\n",
       " 1223666.8,\n",
       " 1311751.4,\n",
       " 1251117.5,\n",
       " 1134022.6,\n",
       " 1287719.1,\n",
       " 1256673.8,\n",
       " 1257282.5,\n",
       " 1379706.6,\n",
       " 1234102.8,\n",
       " 1202724.6,\n",
       " 1226907.1,\n",
       " 1383181.6,\n",
       " 1397309.1,\n",
       " 1346845.1,\n",
       " 1334911.6,\n",
       " 1182319.5,\n",
       " 1453054.5,\n",
       " 1242736.5,\n",
       " 1398739.4,\n",
       " 1328954.5,\n",
       " 1194054.0,\n",
       " 1184558.5,\n",
       " 1291956.2,\n",
       " 1414397.9,\n",
       " 1227378.9,\n",
       " 1279687.5,\n",
       " 1184260.0,\n",
       " 1334153.4,\n",
       " 1216244.2,\n",
       " 1348971.6,\n",
       " 1326517.0,\n",
       " 1260566.1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.625100822647362e-05"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "regr = MLPRegressor(random_state=5, max_iter=100).fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
