{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "#test if gpu is wokring\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print(tf.test.gpu_device_name())\n",
    "\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:\\\\User_Data\\\\Desktop\\\\kan-2\\\\NeuralNetwork\\\\\"\n",
    "import os\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary package\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                133584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 133,793\n",
      "Trainable params: 133,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model complie\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=5565, kernel_initializer='normal', activation='relu'))#input_dim=number of columns original :relu\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))#Here the source is using linear \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_stata(\"CD_icd.dta\")\n",
    "df=pd.read_stata(\"CD_icd.dta\",convert_missing=False)\n",
    "df=df.dropna()\n",
    "x_vars=[\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\",\"month1\",\"month2\",\"month3\",\"month4\",\"month5\",\"month6\"\n",
    "  ,\"month7\",\"month8\",\"month9\",\"month10\",\"month11\",\"month12\",\"male\",\"age\",\"icd_0diab2_365\",\"icd_0liver_365\",\"icd_0cardio_365\",\"icd_0hbp_365\"]\n",
    "for i in df.columns:\n",
    "    if \"icd\" in i and i not in x_vars:\n",
    "        x_vars.append(i)\n",
    "x=df[x_vars]\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#poly = PolynomialFeatures(degree=2,interaction_only=True,include_bias = False)\n",
    "#x=poly.fit_transform(x)\n",
    "y=df[[\"drug_amt\"]]\n",
    "#icd_auri1\n",
    "scaler_x = MinMaxScaler()#able to change to other \n",
    "scaler_y = MinMaxScaler()#able to change\n",
    "#print(scaler_x.fit(x))\n",
    "#xscale=scaler_x.transform(x)\n",
    "#print(scaler_y.fit(y))\n",
    "#yscale=scaler_y.transform(y)\n",
    "xscale=x\n",
    "yscale=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat([y,x],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12943/12943 [==============================] - 132s 10ms/step - loss: 1382736.6250 - mse: 1382736.6250 - mae: 330.1598 - val_loss: 965020.0625 - val_mse: 965020.0625 - val_mae: 321.2055\n",
      "Epoch 2/50\n",
      "12943/12943 [==============================] - 43s 3ms/step - loss: 1348218.0000 - mse: 1348218.0000 - mae: 326.1127 - val_loss: 971103.1250 - val_mse: 971103.1250 - val_mae: 340.1823\n",
      "Epoch 3/50\n",
      "12943/12943 [==============================] - 33s 3ms/step - loss: 1323347.5000 - mse: 1323347.5000 - mae: 323.8049 - val_loss: 994000.2500 - val_mse: 994000.2500 - val_mae: 346.0251\n",
      "Epoch 4/50\n",
      "12943/12943 [==============================] - 31s 2ms/step - loss: 1301544.3750 - mse: 1301544.3750 - mae: 322.2528 - val_loss: 983861.0000 - val_mse: 983861.0000 - val_mae: 337.0035\n",
      "Epoch 5/50\n",
      "12943/12943 [==============================] - 31s 2ms/step - loss: 1283257.6250 - mse: 1283257.6250 - mae: 320.6132 - val_loss: 992999.6875 - val_mse: 992999.6875 - val_mae: 324.5074\n",
      "Epoch 6/50\n",
      "12943/12943 [==============================] - 31s 2ms/step - loss: 1268948.8750 - mse: 1268948.8750 - mae: 318.3886 - val_loss: 993850.7500 - val_mse: 993850.8750 - val_mae: 320.1064\n",
      "Epoch 7/50\n",
      "12943/12943 [==============================] - 27s 2ms/step - loss: 1251135.8750 - mse: 1251135.8750 - mae: 316.0205 - val_loss: 989441.8125 - val_mse: 989441.8125 - val_mae: 329.4178\n",
      "Epoch 8/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1234584.3750 - mse: 1234584.3750 - mae: 314.8127 - val_loss: 1073354.3750 - val_mse: 1073354.3750 - val_mae: 357.0843\n",
      "Epoch 9/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1223433.8750 - mse: 1223433.8750 - mae: 313.6302 - val_loss: 1027023.1250 - val_mse: 1027023.1250 - val_mae: 341.4647\n",
      "Epoch 10/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1213028.5000 - mse: 1213028.5000 - mae: 311.7568 - val_loss: 1026960.8750 - val_mse: 1026960.8750 - val_mae: 349.5144\n",
      "Epoch 11/50\n",
      "12943/12943 [==============================] - 27s 2ms/step - loss: 1201704.5000 - mse: 1201704.6250 - mae: 311.0424 - val_loss: 1001179.6250 - val_mse: 1001179.6250 - val_mae: 330.2646\n",
      "Epoch 12/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1198509.2500 - mse: 1198509.2500 - mae: 309.6978 - val_loss: 1025560.1875 - val_mse: 1025560.1875 - val_mae: 333.3957\n",
      "Epoch 13/50\n",
      "12943/12943 [==============================] - 27s 2ms/step - loss: 1186799.8750 - mse: 1186799.8750 - mae: 308.4236 - val_loss: 1004307.5000 - val_mse: 1004307.3750 - val_mae: 332.7639\n",
      "Epoch 14/50\n",
      "12943/12943 [==============================] - 28s 2ms/step - loss: 1177955.8750 - mse: 1177955.8750 - mae: 308.3601 - val_loss: 1061274.7500 - val_mse: 1061274.7500 - val_mae: 356.9404\n",
      "Epoch 15/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1180498.7500 - mse: 1180498.7500 - mae: 307.4698 - val_loss: 1022123.0625 - val_mse: 1022123.0625 - val_mae: 325.2142\n",
      "Epoch 16/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1169336.3750 - mse: 1169336.3750 - mae: 306.4686 - val_loss: 1024675.0000 - val_mse: 1024675.0000 - val_mae: 342.6606\n",
      "Epoch 17/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1168409.8750 - mse: 1168409.8750 - mae: 306.0070 - val_loss: 1012465.5625 - val_mse: 1012465.5625 - val_mae: 333.0580\n",
      "Epoch 18/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1157734.1250 - mse: 1157734.1250 - mae: 304.8062 - val_loss: 1046681.4375 - val_mse: 1046681.4375 - val_mae: 339.0977\n",
      "Epoch 19/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1152964.7500 - mse: 1152964.7500 - mae: 303.5323 - val_loss: 1027096.6875 - val_mse: 1027096.6875 - val_mae: 349.2066\n",
      "Epoch 20/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1149384.0000 - mse: 1149384.0000 - mae: 303.7471 - val_loss: 1011280.8125 - val_mse: 1011280.8125 - val_mae: 337.3883\n",
      "Epoch 21/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1145892.3750 - mse: 1145892.3750 - mae: 303.2431 - val_loss: 1030389.3750 - val_mse: 1030389.3750 - val_mae: 341.6829\n",
      "Epoch 22/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1140606.5000 - mse: 1140606.5000 - mae: 302.0966 - val_loss: 1009914.8750 - val_mse: 1009914.8750 - val_mae: 337.1957\n",
      "Epoch 23/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1141401.8750 - mse: 1141401.8750 - mae: 301.6719 - val_loss: 1021628.0625 - val_mse: 1021628.0625 - val_mae: 324.8156\n",
      "Epoch 24/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1134484.1250 - mse: 1134484.1250 - mae: 301.4042 - val_loss: 1035160.7500 - val_mse: 1035160.7500 - val_mae: 331.5567\n",
      "Epoch 25/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1137624.3750 - mse: 1137624.2500 - mae: 300.4000 - val_loss: 1027661.1250 - val_mse: 1027661.1250 - val_mae: 346.9781\n",
      "Epoch 26/50\n",
      "12943/12943 [==============================] - 23s 2ms/step - loss: 1134168.6250 - mse: 1134168.6250 - mae: 300.9610 - val_loss: 1032616.3125 - val_mse: 1032616.2500 - val_mae: 326.5450\n",
      "Epoch 27/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1125579.0000 - mse: 1125579.0000 - mae: 300.0251 - val_loss: 1055599.2500 - val_mse: 1055599.2500 - val_mae: 327.8014\n",
      "Epoch 28/50\n",
      "12943/12943 [==============================] - 23s 2ms/step - loss: 1122603.1250 - mse: 1122603.1250 - mae: 299.0410 - val_loss: 1034251.9375 - val_mse: 1034251.9375 - val_mae: 334.8665\n",
      "Epoch 29/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1120482.0000 - mse: 1120482.0000 - mae: 299.3698 - val_loss: 1075128.2500 - val_mse: 1075128.2500 - val_mae: 332.5744\n",
      "Epoch 30/50\n",
      "12943/12943 [==============================] - 28s 2ms/step - loss: 1114766.0000 - mse: 1114766.0000 - mae: 298.9259 - val_loss: 1024779.0625 - val_mse: 1024779.0625 - val_mae: 329.0260\n",
      "Epoch 31/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1117010.7500 - mse: 1117010.7500 - mae: 297.8185 - val_loss: 1022399.5000 - val_mse: 1022399.5000 - val_mae: 324.6368\n",
      "Epoch 32/50\n",
      "12943/12943 [==============================] - 27s 2ms/step - loss: 1111015.2500 - mse: 1111015.2500 - mae: 297.4514 - val_loss: 1006457.0625 - val_mse: 1006457.0625 - val_mae: 340.3449\n",
      "Epoch 33/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1108988.8750 - mse: 1108988.8750 - mae: 297.8830 - val_loss: 1008640.0625 - val_mse: 1008640.0625 - val_mae: 338.6328\n",
      "Epoch 34/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1109468.1250 - mse: 1109468.1250 - mae: 296.9182 - val_loss: 1086140.7500 - val_mse: 1086140.7500 - val_mae: 338.3442\n",
      "Epoch 35/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1102017.6250 - mse: 1102017.6250 - mae: 297.3110 - val_loss: 1054990.2500 - val_mse: 1054990.2500 - val_mae: 323.7415\n",
      "Epoch 36/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1107393.8750 - mse: 1107393.8750 - mae: 296.9171 - val_loss: 1026844.8750 - val_mse: 1026844.8750 - val_mae: 326.1359\n",
      "Epoch 37/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1101001.3750 - mse: 1101001.3750 - mae: 296.5158 - val_loss: 1076154.8750 - val_mse: 1076154.8750 - val_mae: 333.2513\n",
      "Epoch 38/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1098667.2500 - mse: 1098667.2500 - mae: 296.2990 - val_loss: 1033008.3750 - val_mse: 1033008.3750 - val_mae: 329.6224\n",
      "Epoch 39/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1094025.2500 - mse: 1094025.2500 - mae: 295.4554 - val_loss: 1033995.3125 - val_mse: 1033995.3125 - val_mae: 322.9220\n",
      "Epoch 40/50\n",
      "12943/12943 [==============================] - 24s 2ms/step - loss: 1096352.5000 - mse: 1096352.5000 - mae: 295.3165 - val_loss: 1056247.2500 - val_mse: 1056247.2500 - val_mae: 349.4226\n",
      "Epoch 41/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1090304.3750 - mse: 1090304.3750 - mae: 295.2303 - val_loss: 1032415.9375 - val_mse: 1032415.8125 - val_mae: 322.9446\n",
      "Epoch 42/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1091362.2500 - mse: 1091362.2500 - mae: 294.1548 - val_loss: 1019176.0625 - val_mse: 1019176.0625 - val_mae: 326.3252\n",
      "Epoch 43/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1091904.7500 - mse: 1091904.7500 - mae: 294.6747 - val_loss: 1050085.5000 - val_mse: 1050085.5000 - val_mae: 321.9481\n",
      "Epoch 44/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1088477.5000 - mse: 1088477.5000 - mae: 293.9714 - val_loss: 1020133.8125 - val_mse: 1020133.8125 - val_mae: 332.3100\n",
      "Epoch 45/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1089449.3750 - mse: 1089449.3750 - mae: 293.7606 - val_loss: 1041167.6250 - val_mse: 1041167.6250 - val_mae: 325.0792\n",
      "Epoch 46/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1084352.2500 - mse: 1084352.2500 - mae: 293.5426 - val_loss: 1030465.4375 - val_mse: 1030465.4375 - val_mae: 340.9080\n",
      "Epoch 47/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1079366.8750 - mse: 1079366.8750 - mae: 293.4016 - val_loss: 1082281.0000 - val_mse: 1082281.0000 - val_mae: 338.6607\n",
      "Epoch 48/50\n",
      "12943/12943 [==============================] - 26s 2ms/step - loss: 1080037.0000 - mse: 1080037.0000 - mae: 292.5659 - val_loss: 1039895.2500 - val_mse: 1039895.2500 - val_mae: 340.4170\n",
      "Epoch 49/50\n",
      "12943/12943 [==============================] - 27s 2ms/step - loss: 1076632.1250 - mse: 1076632.1250 - mae: 292.8305 - val_loss: 1060893.6250 - val_mse: 1060893.6250 - val_mae: 333.8247\n",
      "Epoch 50/50\n",
      "12943/12943 [==============================] - 25s 2ms/step - loss: 1078100.6250 - mse: 1078100.6250 - mae: 292.8679 - val_loss: 1050027.3750 - val_mse: 1050027.3750 - val_mae: 327.3377\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y, epochs=50, batch_size=50,  verbose=1, validation_split=0.2)#epochs=max steps batch_size=numer of sample will be trained at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.6 GiB for an array with shape (606687, 5565) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-71acd1a7e823>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             return_mean=True)\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean, check_input)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n\u001b[1;32m--> 129\u001b[1;33m                         dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    130\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.6 GiB for an array with shape (606687, 5565) and data type float32"
     ]
    }
   ],
   "source": [
    "#Standard OLS performance\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit (X_train,y_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred=reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mse\n",
    "#mse = ((y_test-y_pred)**2).mean(axis=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"D:\\\\User_Data\\\\Desktop\\\\kan-2\\\\NeuralNetwork\\\\test_for_interaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.625100822647362e-05"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "regr = MLPRegressor(random_state=5, max_iter=100).fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
